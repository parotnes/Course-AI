{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/parotnes/Course-AI/blob/main/hw4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import random\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Ghiob3utPOQ",
        "outputId": "88496981-ba8c-48b8-f53d-9d436e3d5525"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Input and output paths\n",
        "input_folder = '/content/drive/MyDrive/drone_data'\n",
        "output_folder = '/content/drive/MyDrive/drone_data/new_images'\n",
        "\n",
        "# Create the output folder if it doesn't exist\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# Function to read YOLOv8 label file and extract bounding box coordinates\n",
        "def read_yolo_label(label_path):\n",
        "    with open(label_path, 'r') as file:\n",
        "        lines = file.readlines()\n",
        "\n",
        "    # Assuming one object per image for simplicity\n",
        "    label = lines[0].strip().split(' ')\n",
        "    class_id = int(label[0])\n",
        "    x_center, y_center, width, height = map(float, label[1:])\n",
        "\n",
        "    return class_id, x_center, y_center, width, height\n",
        "\n",
        "# Function to crop the image based on YOLOv8 label\n",
        "def crop_image(image_path, label_path, output_path):\n",
        "    image = cv2.imread(image_path)\n",
        "    height, width, _ = image.shape\n",
        "\n",
        "    class_id, x_center, y_center, bbox_width, bbox_height = read_yolo_label(label_path)\n",
        "\n",
        "    # Calculate bounding box coordinates in pixel values\n",
        "    x1 = int((x_center - bbox_width / 2) * width)\n",
        "    y1 = int((y_center - bbox_height / 2) * height)\n",
        "    x2 = int((x_center + bbox_width / 2) * width)\n",
        "    y2 = int((y_center + bbox_height / 2) * height)\n",
        "\n",
        "    # Crop the image based on the bounding box\n",
        "    cropped_image = image[y1:y2, x1:x2]\n",
        "\n",
        "    # Save the cropped image\n",
        "    cv2.imwrite(output_path, cropped_image)\n",
        "\n",
        "# Function to randomly crop a portion of the image\n",
        "def random_crop_image(image_path, output_path, crop_size=(224, 224)):\n",
        "    image = cv2.imread(image_path)\n",
        "    height, width, _ = image.shape\n",
        "\n",
        "    # Randomly select top-left coordinates for cropping\n",
        "    top_left_x = random.randint(0, width - crop_size[1])\n",
        "    top_left_y = random.randint(0, height - crop_size[0])\n",
        "\n",
        "    # Crop the image\n",
        "    cropped_image = image[top_left_y:top_left_y + crop_size[0], top_left_x:top_left_x + crop_size[1]]\n",
        "\n",
        "    # Save the cropped image\n",
        "    cv2.imwrite(output_path, cropped_image)\n",
        "\n",
        "# Process each image and corresponding label\n",
        "for filename in os.listdir(input_folder):\n",
        "    if filename.endswith(\".jpg\") or filename.endswith(\".jpeg\"):\n",
        "        image_path = os.path.join(input_folder, filename)\n",
        "        label_path = os.path.join(input_folder, os.path.splitext(filename)[0] + \".txt\")\n",
        "\n",
        "        if os.path.exists(label_path):\n",
        "            # Process image based on YOLOv8 label\n",
        "            output_path_yolo = os.path.join(output_folder, \"yolo_\" + filename)\n",
        "            crop_image(image_path, label_path, output_path_yolo)\n",
        "\n",
        "            # Process image with random crop\n",
        "            output_path_random = os.path.join(output_folder, \"random_\" + filename)\n",
        "            random_crop_image(image_path, output_path_random)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "0cAnOqb3wP8g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from keras.preprocessing import image\n",
        "from keras.preprocessing.image import img_to_array, array_to_img\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "# Function to convert image to black and white with a resolution of 28x28\n",
        "def preprocess_image(file_path):\n",
        "    img = Image.open(file_path).convert('L')  # Convert to grayscale\n",
        "    img = img.resize((28, 28), Image.ANTIALIAS)  # Resize to 28x28\n",
        "    img_array = img_to_array(img)\n",
        "    img_array = img_array / 255.0  # Normalize pixel values\n",
        "    return img_array\n",
        "\n",
        "# Define the source and destination folders\n",
        "source_folder = '/content/drive/MyDrive/drone_data/new_images'\n",
        "destination_folder = '/content/drive/My Drive/drone_data/new_images/processed_images'\n",
        "\n",
        "# Create the destination folder if it doesn't exist\n",
        "if not os.path.exists(destination_folder):\n",
        "    os.makedirs(destination_folder)\n",
        "\n",
        "# Iterate through each image in the source folder\n",
        "for filename in os.listdir(source_folder):\n",
        "    if filename.endswith(('.jpg', '.png', '.jpeg')):\n",
        "        file_path = os.path.join(source_folder, filename)\n",
        "        # Preprocess the image\n",
        "        processed_img_array = preprocess_image(file_path)\n",
        "\n",
        "        # Save the processed image to the destination folder using cv2\n",
        "        processed_img_path = os.path.join(destination_folder, f\"bw_{filename}\")\n",
        "        cv2.imwrite(processed_img_path, processed_img_array * 255)\n",
        "\n",
        "print(\"Image processing and saving complete.\")\n"
      ],
      "metadata": {
        "id": "G-AQsGCQ7Ic2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "# Path to the folder containing your pictures\n",
        "folder_path = '/content/drive/My Drive/drone_data/new_images/processed_images'\n",
        "\n",
        "# Create subdirectories if they don't exist\n",
        "os.makedirs(os.path.join(folder_path, 'drone'), exist_ok=True)\n",
        "os.makedirs(os.path.join(folder_path, 'no_drone'), exist_ok=True)\n",
        "\n",
        "# Lists to store pictures\n",
        "drone = []\n",
        "no_drone = []\n",
        "\n",
        "# Iterate through files in the folder\n",
        "for filename in os.listdir(folder_path):\n",
        "    if filename.startswith('bw_random'):\n",
        "        # Move to no_drone folder\n",
        "        no_drone.append(filename)\n",
        "        shutil.move(os.path.join(folder_path, filename), os.path.join(folder_path, 'no_drone', filename))\n",
        "    elif filename.startswith('bw_yolo'):\n",
        "        # Move to drone folder\n",
        "        drone.append(filename)\n",
        "        shutil.move(os.path.join(folder_path, filename), os.path.join(folder_path, 'drone', filename))\n",
        "\n",
        "# Print the lists\n",
        "print('drone:', drone)\n",
        "print('no_drone:', no_drone)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OQQGOr1kDwTM",
        "outputId": "ba0de98e-d7d2-4f65-d178-edcb3568c201"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "drone: []\n",
            "no_drone: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "\n",
        "# Set the path to the main folder containing subfolders\n",
        "main_folder_path = '/content/drive/My Drive/drone_data/new_images/processed_images'\n",
        "\n",
        "# List to store image paths and corresponding labels\n",
        "image_paths = []\n",
        "labels = []\n",
        "\n",
        "# Define label classes\n",
        "class_names = ['no_drone', 'drone']\n",
        "\n",
        "# Iterate through each class folder\n",
        "for class_name in class_names:\n",
        "    class_folder = os.path.join(main_folder_path, class_name)\n",
        "\n",
        "    # Iterate through each image in the class folder\n",
        "    for filename in os.listdir(class_folder):\n",
        "        if filename.endswith('.jpg'):  # assuming the images are in JPG format\n",
        "            img_path = os.path.join(class_folder, filename)\n",
        "\n",
        "            # Append the image path and corresponding label to the lists\n",
        "            image_paths.append(img_path)\n",
        "            labels.append(class_names.index(class_name))\n",
        "\n",
        "# Split the data into training and validation sets\n",
        "train_image_paths, val_image_paths, train_labels, val_labels = train_test_split(\n",
        "    image_paths, labels, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Function to load and preprocess an image\n",
        "def load_and_preprocess_image(img_path, label):\n",
        "    # Extract the path from the symbolic tensor\n",
        "    img_path = img_path.numpy().decode('utf-8')\n",
        "\n",
        "    img = load_img(img_path, target_size=(256, 256))  # adjust target_size as needed\n",
        "    img_array = img_to_array(img) / 255.0  # normalize pixel values to [0, 1]\n",
        "    return img_array, label\n",
        "\n",
        "train_labels = tf.convert_to_tensor(train_labels, dtype=tf.int64)\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_image_paths, train_labels))\n",
        "train_dataset = train_dataset.map(lambda x, y: tf.py_function(load_and_preprocess_image, [x, y], [tf.float32, tf.int64]))\n",
        "\n",
        "\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((val_image_paths, val_labels))\n",
        "val_dataset = val_dataset.map(lambda x, y: tf.py_function(load_and_preprocess_image, [x, y], [tf.float32, tf.int64]))\n",
        "val_dataset = val_dataset.batch(32)\n",
        "\n",
        "# Display the first batch of images and labels (for verification)\n",
        "for batch in train_dataset.take(1):\n",
        "    images, labels = batch\n",
        "    print(images.shape)  # shape of the images batch\n",
        "    print(labels)  # corresponding labels\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "4iXp_gFwE4XE",
        "outputId": "4c56e8c4-52b7-46c7-970c-1912649aaa88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-d5b3df9fbb16>\u001b[0m in \u001b[0;36m<cell line: 53>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;31m# Display the first batch of images and labels (for verification)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m     \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# shape of the images batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    807\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    808\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 809\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    810\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    811\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    770\u001b[0m     \u001b[0;31m# to communicate that there is no more data to iterate over.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    771\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecution_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSYNC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 772\u001b[0;31m       ret = gen_dataset_ops.iterator_get_next(\n\u001b[0m\u001b[1;32m    773\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    774\u001b[0m           \u001b[0moutput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36miterator_get_next\u001b[0;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[1;32m   3026\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3027\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3028\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3029\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3030\u001b[0m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   5886\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mNoReturn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5887\u001b[0m   \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5888\u001b[0;31m   \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5889\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: {{function_node __wrapped__IteratorGetNext_output_types_2_device_/job:localhost/replica:0/task:0/device:CPU:0}} ValueError: Tensor conversion requested dtype int64 for Tensor with dtype int32: <tf.Tensor: shape=(), dtype=int32, numpy=0>\nTraceback (most recent call last):\n\n  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/script_ops.py\", line 268, in __call__\n    return func(device, token, args)\n\n  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/script_ops.py\", line 146, in __call__\n    outputs = self._call(device, args)\n\n  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/script_ops.py\", line 162, in _call\n    outputs = [\n\n  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/script_ops.py\", line 163, in <listcomp>\n    _maybe_copy_to_context_device(self._convert(x, dtype=dtype),\n\n  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/script_ops.py\", line 130, in _convert\n    return ops.convert_to_tensor(value, dtype=dtype)\n\n  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/profiler/trace.py\", line 183, in wrapped\n    return func(*args, **kwargs)\n\n  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/ops.py\", line 698, in convert_to_tensor\n    return tensor_conversion_registry.convert(\n\n  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/tensor_conversion_registry.py\", line 209, in convert\n    return overload(dtype, name)  #  pylint: disable=not-callable\n\n  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/ops.py\", line 593, in __tf_tensor__\n    return super().__tf_tensor__(dtype, name)\n\n  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/tensor.py\", line 762, in __tf_tensor__\n    raise ValueError(\n\nValueError: Tensor conversion requested dtype int64 for Tensor with dtype int32: <tf.Tensor: shape=(), dtype=int32, numpy=0>\n\n\n\t [[{{node EagerPyFunc}}]] [Op:IteratorGetNext] name: "
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOfVLimc+6qpMIK7FDJhcOx",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}